#!/usr/bin/env python3
"""
Script simplifi√© pour importer les donn√©es JSON dans la base
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from database.models import SessionLocal, JobOffer
import json
from datetime import datetime
from sqlalchemy import func

def import_and_show():
    """Importer les donn√©es et afficher les statistiques"""
    print("üìÇ IMPORTATION DES DONN√âES JSON DANS MySQL")
    print("=" * 50)
    
    # Importer les donn√©es JSON existantes
    import_json_data()
    
    # Afficher les statistiques
    show_statistics()
    
    print("\n‚úÖ Base de donn√©es peupl√©e avec succ√®s!")

def import_json_data():
    """Importer les donn√©es des fichiers JSON dans MySQL"""
    db = SessionLocal()
    
    json_files = [
        "data/offres_cdd.json",
        "data/offres_emploi.json",
        "data/offres_toutes.json"
    ]
    
    imported_count = 0
    skipped_count = 0
    
    for json_file in json_files:
        if not os.path.exists(json_file):
            print(f"   ‚ö†  Fichier non trouv√©: {json_file}")
            continue
            
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                # Format des fichiers
                if isinstance(data, dict) and 'offers' in data:
                    offers_data = data['offers']
                elif isinstance(data, list):
                    offers_data = data
                else:
                    print(f"   ‚ö†  Format invalide dans {json_file}")
                    continue
                
                print(f"   üìñ Lecture de {json_file}: {len(offers_data)} offres")
                
                for i, offer_data in enumerate(offers_data, 1):
                    link = offer_data.get('link', '')
                    if not link:
                        skipped_count += 1
                        continue
                    
                    # V√©rifier si l'offre existe d√©j√†
                    existing = db.query(JobOffer.id).filter(
                        JobOffer.link == link
                    ).first()
                    
                    if not existing:
                        # Cr√©er une nouvelle offre
                        try:
                            job_offer = JobOffer(
                                title=offer_data.get('title', 'Non sp√©cifi√©')[:500],
                                link=link[:500],
                                company=offer_data.get('company', 'Non sp√©cifi√©')[:200],
                                date_posted=str(offer_data.get('date', ''))[:100],
                                contract_type=offer_data.get('contrat', 'Non sp√©cifi√©')[:100],
                                sector=offer_data.get('secteur', 'Non sp√©cifi√©')[:200],
                                job_title=offer_data.get('metier', 'Non sp√©cifi√©')[:200],
                                location=offer_data.get('location', 'Non sp√©cifi√©')[:200],
                                description=offer_data.get('description', '')[:1000],
                                ia_risk_score=float(offer_data.get('ia_risk_score', 5.0)),
                                ia_risk_level=offer_data.get('ia_risk_level', 'Moyen')[:50],
                                suggestions=', '.join(offer_data.get('suggestions', []))[:1000],
                                scraped_at=datetime.utcnow(),
                                is_active=True
                            )
                            db.add(job_offer)
                            imported_count += 1
                            
                            # Commit p√©riodiquement pour √©viter les transactions trop longues
                            if imported_count % 10 == 0:
                                db.commit()
                                print(f"      ‚Üí {imported_count} offres import√©es...")
                                
                        except Exception as e:
                            print(f"      ‚ùå Erreur cr√©ation offre {i}: {e}")
                            skipped_count += 1
                    else:
                        skipped_count += 1  # Offre d√©j√† existante
            
            db.commit()
            print(f"   ‚úÖ {json_file}: import termin√©")
            
        except Exception as e:
            print(f"‚ùå Erreur avec {json_file}: {e}")
            db.rollback()
            import traceback
            traceback.print_exc()
    
    db.close()
    print(f"\nüìä R√âSULTAT FINAL:")
    print(f"   ‚Üí {imported_count} offres import√©es")
    print(f"   ‚Üí {skipped_count} offres ignor√©es (doublons ou invalides)")

def show_statistics():
    """Afficher les statistiques de la base"""
    db = SessionLocal()
    
    try:
        total = db.query(func.count(JobOffer.id)).scalar() or 0
        
        print(f"\nüìä STATISTIQUES DE LA BASE:")
        print(f"   ‚Ä¢ Total offres: {total}")
        
        if total > 0:
            # Distribution des risques
            risk_levels = ['√âlev√©', 'Moyen', 'Faible']
            print(f"\n   üìà DISTRIBUTION DES RISQUES:")
            for level in risk_levels:
                count = db.query(func.count(JobOffer.id)).filter(
                    JobOffer.ia_risk_level == level
                ).scalar() or 0
                percentage = (count / total * 100) if total > 0 else 0
                print(f"     ‚Ä¢ {level}: {count} offres ({percentage:.1f}%)")
            
            # Top m√©tiers
            top_jobs = db.query(
                JobOffer.job_title,
                func.count(JobOffer.id).label('count')
            ).filter(
                JobOffer.job_title != '',
                JobOffer.job_title != 'Non sp√©cifi√©'
            ).group_by(
                JobOffer.job_title
            ).order_by(
                func.count(JobOffer.id).desc()
            ).limit(5).all()
            
            if top_jobs:
                print(f"\n   üèÜ TOP 5 M√âTIERS:")
                for job, count in top_jobs:
                    print(f"     ‚Ä¢ {job}: {count} offres")
            
            # Top secteurs
            top_sectors = db.query(
                JobOffer.sector,
                func.count(JobOffer.id).label('count')
            ).filter(
                JobOffer.sector != '',
                JobOffer.sector != 'Non sp√©cifi√©'
            ).group_by(
                JobOffer.sector
            ).order_by(
                func.count(JobOffer.id).desc()
            ).limit(5).all()
            
            if top_sectors:
                print(f"\n   üè¢ TOP 5 SECTEURS:")
                for sector, count in top_sectors:
                    print(f"     ‚Ä¢ {sector}: {count} offres")
                    
            # Exemple d'offres
            print(f"\n   üìù EXEMPLES D'OFFRES:")
            sample_offers = db.query(JobOffer).limit(3).all()
            for i, offer in enumerate(sample_offers, 1):
                print(f"     {i}. {offer.title[:40]}...")
                print(f"        M√©tier: {offer.job_title}")
                print(f"        Risque: {offer.ia_risk_score}/10 ({offer.ia_risk_level})")
                print()
                
        else:
            print("   ‚ö†  Base de donn√©es vide - Essayez le scraping manuel")
            
    except Exception as e:
        print(f"‚ùå Erreur statistiques: {e}")
        import traceback
        traceback.print_exc()
    finally:
        db.close()

def main():
    print("üóÑÔ∏è  IMPORTATION DE DONN√âES DANS MySQL")
    print("=" * 50)
    print("‚ÑπÔ∏è  Les tables existent d√©j√† (cr√©√©es par repair_database.py)")
    print("‚ÑπÔ∏è  Importation des fichiers JSON...")
    
    import_and_show()
    
    print("\nüéØ PROCHAINES √âTAPES:")
    print("1. D√©marrer l'API: python3 run.py")
    print("2. Tester: curl http://localhost:5000/api/health")
    print("3. Scraper plus de donn√©es: python3 scrapers/run_scraper.py")

if __name__ == "__main__":
    main()